算法博客
https://blog.csdn.net/fuxuemingzhu/article/details/101900729
https://blog.csdn.net/fuxuemingzhu


注意 在树的递归中
使用了 if root.left:
         xxx
      if root.right:
         xxx
这样的话在最前面（递归外面）一定要有一个判断，即if root is None:
                                    return


注意，其实
path.append(xx)
for i in range(size):
    dfs(xx)
path.pop()
等同于
for i in range(size):
    path.append(xx)
    dfs(xx)
    path.pop()
只不过可能在下面这种方式中，有时候需要用到i,所以需要写成这样
有个例题比如79题，这个题就可以将回溯中的路径选择弄到外面


注意在回溯中
全排列2问题中，i>0是为了nums[i-1] == nums[i]可以进行比较
在子集2问题中，i>start之后进行nums[i-1] == nums[i],此时i>start可以确保是在当前节点的第二条路下



注意200题和994题目的区别：
200题需要遍历网格中的每一个节点，所以一开始遍历的时候就要先将头节点的marked标记为True
994题第一次已经将所有的烂橘子都入队列了

在全排列的题目中，起点其实是一个空列表[]，所以这个时候按回溯模板递归，在for i in range(len)内部进行标记判断和进行路径选择等等
在二维图中，需要遍历每一个点，所以这个时候可以在外部两层for循环中先将marked标记为true，然后在pop
          然后在dfs中进行标准的操作，append dfs pop
在二维图中，也可以直接在DFS中进行判断，在dfs总的for循环上面进行标记，然后在内部判断新的点是否被标记，for循环结束之后需要pop



经常把 == 和 = 弄混导致错误！！！！
需要打断点看！


74题中，二维变成一维的方法
matrix[mid // col][mid % col]


在子集中:
if start < i and nums[i] == nums[i - 1]:
# 这里的 i 是指回溯树中同一层（当前层）中的其他节点，start指层数
'''
          start i
for i in  1     2 3 4
for i in  2     3 4
for i in  3     4
for i in  4
'''
当限制了 i>start
之后因为每次递归的时候都是i+1,所以每一层的第一个和上一层的第一个都不会相同，所以不会出现子集112那种情况

在全排列中
这里的 i 为每一层中的第i个元素，i>0 只是为了判断 i-1 的值
used[i - 1]中的i-1是同一层中的i的前一个节点，这里要确保used[i-1]是False
则证明i-1是刚刚遍历过的，同一层再次出现相同的元素就continue
避免下一层第元素和上一层中的元素一样时也被误kill
比如 112
1
1
2
第一层中的1，和下一层中的元素相同，因为全排列没有取 start=i+1 这种操作，所以要避免出现这种情况

if i > 0 and nums[i] == nums[i - 1] and used[i - 1] is False:
这这里如果排完序之后，则num[i] 和 num[i-1]是同一层中相邻的两个元素

总结
其实i在行和列方向上都是增加的
    i+1
i+1 1   2   3
    2   3
    3


在轴上有交点！！！
比如在X轴有交点 看投影
设(a,b)是从 a 点到 b 点的一个线段
即 A(x1,x2)   B(x3,x4)
如果线段A和B有交集
则需要
min(A[1],B[1]) > max(A[0],B[0])   !!!!!请牢记 两点最大值的最小值必须大于两点最小值的最大值！！！！！！！


如果在树，回溯，等递归中：
    如果在子条件判断了比如if root.left:
                        xxx
    这样只需要在最上面判断一下if root.left and root.right:
    不需要先判断if root:
    可以在递归函数外进行一次判断就可以


java中一切皆对象
Java中的动态代理类似于Python中的装饰器，类似于Scala中的隐式转换函数！本质上都是为了OCP原则，即开放封闭原则


在Java中，面向接口开发很重要！面向接口开发，实际上就是满足多态性！多态性就是为了实现方法的复用，继承是为了实现代码的复用
面向接口初级版本:
ISkill iskill;
switch (name){
case "Diana" :
       iskill = new Diana()
       break
case "Irelia":
        iskill = new Irelia()
        break
default:
        thrown new Exception
    iskill.r()
}
面向接口高级版本
ISkill iskill = HeroFactory.getHero(name)
iskill.r()
class HeroFactory{
ISkill getHero(name){
ISkill iskill;
Class<?> cla = Class.forname(name);
Object obj = cla.newInstance();
return (ISkill)Obj;
}
}


java中的try catch用来捕获异常，如果当前发生异常不处理，可以在类中throw一个异常，让上级去处理，如果都处理不了，就直接over

一个很棒的点
在Scala中，函数可以被直接注册为udf！！这点很棒啊!
在Scala中，方法转函数只需要在方法后面加一个下划线就可以
比如
    import spark.implicits._

    // 注册UDF
    spark.udf.register("timezoneToTimestamp", timezoneToTimestamp _)

使用的时候
    // ResultTable
    val resultTable = inputTable
      .select(from_json(col("value").cast("string"), DataType.fromJson(jsonSchema)).as("value"))
      .select($"value.*")
      .withColumn("timestamp", functions.callUDF("timezoneToTimestamp", functions.col("eventTime"),lit("yyyy-MM-dd HH:mm:ss"),lit("GMT+8")))
      .filter($"timestamp".isNotNull && $"eventType".isNotNull && $"userID".isNotNull)
      // 重复记录到达的时间上限
      .withWatermark("timestamp", "10 seconds")
      .dropDuplicates("timestamp","eventType","userID")
      .select($"eventTime",$"eventType",$"userID")


注意
spark中mapWithState只会输出当前批次有更新的数据的结果，不会全部显示
其实就减轻了state的压力
相当于sparkstructured中的 update模式！
这里要说一个structured中的几个模式
（1）完全模式（Complete Mode）

        整个更新的结果表（Result Table）将被写入到外部存储。这取决于外部连接决定如何操作整个表的写入。

（2）追加模式（Append Mode）

        只有从上一次触发后追加到结果表中新行会被写入到外部存储。适用于已经存在结果表中的行不期望被改变的查询。

（3）更新模式（Update Mode）
       只有从上一次触发后在结果表中更新的行将会写入外部存储（Spark 2.1.1之后才可用）。这种模式不同于之前的完全模式，它仅仅输出上一次触发后改变的行。如果查询中不包含聚合，这种模式与追加模式等价的。

mapWtihState相当于update
这里要再说一下flink中的几个更新模式！
flink中的upsert和restract流
restract会有两个消息，一个是false一个是true
upsert只有一条消息，一个true
我们可以在下流中处理这些消息，比如对于restact消息，可以在下游中过滤掉false中的语句


Java中的反射和动态代理
比如一个类，这个类中的方法有100，可以用来做权限控制，现在我们有一个需求是要在权限控制之前加一个验证码短信的功能
总不能每一个方法前面都去加一个验证功能吧？
这个时候我们就需要使用动态代理，来动态增强一些功能！