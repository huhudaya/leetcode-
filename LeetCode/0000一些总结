算法博客
https://blog.csdn.net/fuxuemingzhu/article/details/101900729
https://blog.csdn.net/fuxuemingzhu


注意 在树的递归中
使用了 if root.left:
         xxx
      if root.right:
         xxx
这样的话在最前面（递归外面），即调用递归函数之前一定要有一个判断，即if root is None:
                                                                 return
但是在递归函数里面可以不用判断


注意，其实
path.append(xx)
for i in range(size):
    dfs(xx)
path.pop()
等同于
for i in range(size):
    path.append(xx)
    dfs(xx)
    path.pop()
只不过可能在下面这种方式中，有时候需要用到i,所以需要写成这样
有个例题比如79题，这个题就可以将回溯中的路径选择弄到外面


注意在回溯中
全排列2问题中，i>0是为了nums[i-1] == nums[i]可以进行比较
在子集2问题中，i>start之后进行nums[i-1] == nums[i],此时i>start可以确保是在当前节点的第二条路下



注意200题和994题目的区别：
200题需要遍历网格中的每一个节点，所以一开始遍历的时候就要先将头节点的marked标记为True
994题第一次已经将所有的烂橘子都入队列了

在全排列的题目中，起点其实是一个空列表[]，所以这个时候按回溯模板递归，在for i in range(len)内部进行标记判断和进行路径选择等等
在二维图中，需要遍历每一个点，所以这个时候可以在外部两层for循环中先将marked标记为true，然后在pop
          然后在dfs中进行标准的操作，append dfs pop
在二维图中，也可以直接在DFS中进行判断，在dfs总的for循环上面进行标记，然后在内部判断新的点是否被标记，for循环结束之后需要pop



经常把 == 和 = 弄混导致错误！！！！
需要打断点看！


74题中，二维变成一维的方法
matrix[mid // col][mid % col]


在子集中:
if start < i and nums[i] == nums[i - 1]:
# 这里的 i 是指回溯树中同一层（当前层）中的其他节点，start指层数
'''
          start i
for i in  1     2 3 4
for i in  2     3 4
for i in  3     4
for i in  4
'''
当限制了 i>start
之后因为每次递归的时候都是i+1,所以每一层的第一个和上一层的第一个都不会相同，所以不会出现子集112那种情况

在全排列中
这里的 i 为每一层中的第i个元素，i>0 只是为了判断 i-1 的值
used[i - 1]中的i-1是同一层中的i的前一个节点，这里要确保used[i-1]是False
则证明i-1是刚刚遍历过的，同一层再次出现相同的元素就continue
避免下一层第元素和上一层中的元素一样时也被误kill
比如 112
1
1
2
第一层中的1，和下一层中的元素相同，因为全排列没有取 start=i+1 这种操作，所以要避免出现这种情况

if i > 0 and nums[i] == nums[i - 1] and used[i - 1] is False:
这这里如果排完序之后，则num[i] 和 num[i-1]是同一层中相邻的两个元素

总结
其实i在行和列方向上都是增加的
    i+1
i+1 1   2   3
    2   3
    3


在轴上有交点！！！
比如在X轴有交点 看投影
设(a,b)是从 a 点到 b 点的一个线段
即 A(x1,x2)   B(x3,x4)
如果线段A和B有交集
则需要
min(A[1],B[1]) > max(A[0],B[0])   !!!!!请牢记 两点最大值的最小值必须大于两点最小值的最大值！！！！！！！


如果在树，回溯，等递归中：
    如果在子条件判断了比如if root.left:
                        xxx
    这样只需要在最上面判断一下if root.left and root.right:
    不需要先判断if root:
    可以在递归函数外进行一次判断就可以


java中一切皆对象
Java中的动态代理类似于Python中的装饰器，类似于Scala中的隐式转换函数！本质上都是为了OCP原则，即开放封闭原则


在Java中，面向接口开发很重要！面向接口开发，实际上就是满足多态性！多态性就是为了实现方法的复用，继承是为了实现代码的复用
面向接口初级版本:
ISkill iskill;
switch (name){
case "Diana" :
       iskill = new Diana()
       break
case "Irelia":
        iskill = new Irelia()
        break
default:
        thrown new Exception
    iskill.r()
}
面向接口高级版本
ISkill iskill = HeroFactory.getHero(name)
iskill.r()
class HeroFactory{
ISkill getHero(name){
ISkill iskill;
Class<?> cla = Class.forname(name);
Object obj = cla.newInstance();
return (ISkill)Obj;
}
}


java中的try catch用来捕获异常，如果当前发生异常不处理，可以在类中throw一个异常，让上级去处理，如果都处理不了，就直接over

一个很棒的点
在Scala中，函数可以被直接注册为udf！！这点很棒啊!
在Scala中，方法转函数只需要在方法后面加一个下划线就可以
比如
    import spark.implicits._

    // 注册UDF
    spark.udf.register("timezoneToTimestamp", timezoneToTimestamp _)

使用的时候
    // ResultTable
    val resultTable = inputTable
      .select(from_json(col("value").cast("string"), DataType.fromJson(jsonSchema)).as("value"))
      .select($"value.*")
      .withColumn("timestamp", functions.callUDF("timezoneToTimestamp", functions.col("eventTime"),lit("yyyy-MM-dd HH:mm:ss"),lit("GMT+8")))
      .filter($"timestamp".isNotNull && $"eventType".isNotNull && $"userID".isNotNull)
      // 重复记录到达的时间上限
      .withWatermark("timestamp", "10 seconds")
      .dropDuplicates("timestamp","eventType","userID")
      .select($"eventTime",$"eventType",$"userID")


注意
spark中mapWithState只会输出当前批次有更新的数据的结果，不会全部显示
其实就减轻了state的压力
相当于sparkstructured中的 update模式！
这里要说一个structured中的几个模式
（1）完全模式（Complete Mode）

        整个更新的结果表（Result Table）将被写入到外部存储。这取决于外部连接决定如何操作整个表的写入。

（2）追加模式（Append Mode）

        只有从上一次触发后追加到结果表中新行会被写入到外部存储。适用于已经存在结果表中的行不期望被改变的查询。

（3）更新模式（Update Mode）
       只有从上一次触发后在结果表中更新的行将会写入外部存储（Spark 2.1.1之后才可用）。这种模式不同于之前的完全模式，它仅仅输出上一次触发后改变的行。如果查询中不包含聚合，这种模式与追加模式等价的。

mapWtihState相当于update
这里要再说一下flink中的几个更新模式！
flink中的upsert和restract流
restract会有两个消息，一个是false一个是true
upsert只有一条消息，一个true
我们可以在下流中处理这些消息，比如对于restact消息，可以在下游中过滤掉false中的语句


Java中的反射和动态代理
比如一个类，这个类中的方法有100，可以用来做权限控制，现在我们有一个需求是要在权限控制之前加一个验证码短信的功能
总不能每一个方法前面都去加一个验证功能吧？
这个时候我们就需要使用动态代理，来动态增强一些功能！


如果在调用dfs之前进行了标记或者使用了，那么就可以使用标准的回溯模板，如果第一次没有使用或者标记，比如79题中的第一种解法，这个时候在dfs内部的for循环外面就需要一次数据的判断
# 79题目中的标准回溯模板，即第一次已经将该元素标记为已使用，所以可以使用标准的回溯模板，如果第一次，即调用dfs之前并没有标记使用，这个时候需要在dfs递归函数中的for循环外面先进行一次标记使用
# 类比于257题目中，在调用dfs之前使用了helper(root, [str(root.val)], result)，这就相当于在dfs之前


贪心算法之区间调度问题
    按start排序
区间问题之合并相交区间
    按end排序


关于数字0~n-1或则1~n的这些题目：
    当范围是0~n-1时候
        1.首先考虑抽屉法，当数字范围是0-n-1的n个数时，使用抽屉法将自己换回到对应索引的位置上
        3.考虑异或运算
        4.考虑sum(n) - sum(nums)
        5.当考虑缺失元素时候，使用减法或者异或
        6.当考虑重复元素的时候，使用抽屉法
    当是1~n的时候：
        1.使用绝对值，因为范围是从1开始的，所以是可行的

bfs和dfs相关问题
1.一般涉及到全路径的问题，比如要确定一条完整的路径，这个时候就需要dfs+回溯，单纯bfs每次的路径都是一样的，所以不可取
（对于dfs求全路径问题，一般还可以用一个level变量表示当前的层数！）
2.一般bfs用来解决最短路径问题，比如求A到B的最短路径，当遇见B就可以直接return，不用全部遍历完，这点是和DFS最大的不同，dfs需要全部遍历完全之后才能确定最小值，比如111题目
3.如果不涉及到回溯，则一般情况下dfs和bfs都是可以的
4.二叉树问题中，如果要求最大或者最小值，多考虑用一个全局变量记录比较结果值


链表中
使用了dummy,然后dummy.next = head
这样取中间节点的时候
下边界
fast,slow = head,head
while fast and fast.next:
    fast = fast.next.next
    slow = slow.next
上边界
fast,slow = dummy
while fast and fast.next:
    fast = fast.next.next
    slow = slow.next