1.JDK和JRE的区别

2.java的基本数据类型
    数据类型	大小
    byte(字节)	1个字节(8位)
    shot(短整型) 	2个字节(16位)
    int(整型)	4个字节(32位)
    long(长整型) 	8个字节(32位)
    float(浮点型)	4个字节(32位)
    double(双精度)	8个字节(64位)
    char(字符型)	2个字节(16位)
    boolean(布尔型)	1位
    附加：
     String是基本数据类型吗?(String不是基本数据类型)
     String的长度是多少，有限制?(长度受内存大小的影响)

3.创建线程的方式
    浅谈三种方式优劣势
    通过继承Thread类或实现Runnable、Callable接口都可以实现多线程，不过实现Runnable接口与实现Callable接口的方式基本相同，只是Callable接口里定义的方法有返回值，可以声明抛出异常而已。因此可以将实现Runnable接口和实现Callable接口归为一种方式。这种方式与继承Thread方式之间的主要差别如下。
    1.采用实现Runnable、Callable接口的方式创建多线程的优缺点：
优势：（1）线程类只是实现了Runnable接口与Callable接口，还可以继承其他类。
     （2）在这种方式下，多个线程可以共享一个target对象，所以非常适合多个相同线程来处理同一份资源的情况，从而可以将CPU、代码和数据分开，形成清晰的模型，较好地体现了面向对象的思想。
劣势：编程稍稍复杂，如果需要访问当前线程，则必须使用Thread.currentThread（）方法。
    2.采用继承Thread类的方法创建多线程的优缺点：
劣势：因为线程类已经继承了Thread类，所以不能再继承其他父类。
优势：编写简单，如果需要访问当前线程，则无须使用Thread.currentThread（）方法，直接使用this即可获得当前线程。
五、总结
    鉴于上面分析，因此一般推荐采用实现Runnable接口、Callable接口的方式来创建多线程。

4.什么是死锁
    线程死锁是指由于两个或者多个线程互相持有对方所需要的资源，导致这些线程处于等待状态，无法前往执行。
    当线程进入对象的synchronized代码块时，便占有了资源，直到它退出该代码块或者调用wait方法，才释放资源，在此期间，其他线程将不能进入该代码块。
    当线程互相持有对方所需要的资源时，会互相等待对方释放资源，如果线程都不主动释放所占有的资源，将产生死锁。

当然死锁的产生是必须要满足一些特定条件的：
    1.互斥条件：进程对于所分配到的资源具有排它性，即一个资源只能被一个进程占用，直到被该进程释放
    2.请求和保持条件：一个进程因请求被占用资源而发生阻塞时，对已获得的资源保持不放。
    3.不剥夺条件：任何一个资源在没被该进程释放之前，任何其他进程都无法对他剥夺占用
    4.循环等待条件：当发生死锁时，所等待的进程必定会形成一个环路（类似于死循环），造成永久阻塞。

5.java中class.forName和classLoader加载类的区分
    总结
        ClassLoader.load()方法加载一个类的时候不会触发这个类初始化（有关类初始化的相关内容请查看我的另外一篇详细的介绍）
        自然static静态代码块就不会被执行
        Class.forName()方法加载一个类之后会强制这个类初始化
     java中class.forName和classLoader都可用来对类进行加载。
     前者除了将类的.class文件加载到jvm中之外，还会对类进行解释，执行类中的static块。
     而classLoader只干一件事情，就是将.class文件加载到jvm中，不会执行static中的内容,只有在newInstance才会去执行static块。Class.forName(name, initialize, loader)带参函数也可控制是否加载static块。并且只有调用了newInstance()方法采用调用构造函数，创建类的对象

        下面说一下两者具体的执行过程
    1.LoadClass（）方法加载类及初始化过程：
        类加载（loadclass（））（加载）——》newInstance（）（链接+初始化）
        newInstance（）:
        （开始连接）静态代码块——》普通变量分配准备（a=0;b=0;c=null）——》（开始初始化）普通变量赋值（a=1;b=2;c=”haha”）——》构造方法——》初始化成功。

    2.Class.forName(Stirng className)一个参数方法加载类及初始化过程：
        类加载(Class.forName())（加载）——》静态代码块——》newInstance（）（链接+初始化）

    newInstance（）：
        （开始连接）普通变量分配准备（a=0;b=0;c=null）——》（开始初始化）普通变量赋值（a=1;b=2;c=”haha”）——》构造方法——》初始化成功。


6.谈谈RDD
    1为什么会产生RDD
（1） 传统的MapReduce虽然具有自动容错、平衡负载和可拓展性的优点，但是其最大缺点是采用非循环式的数据流模型，使得在迭代计算式要进行大量的磁盘IO操作。RDD正是解决这一缺点的抽象方法。
（2） RDD是Spark提供的最重要的抽象的概念，它是一种有容错机制的特殊集合，可以分布在集群的节点上，以函数式编操作集合的方式，进行各种并行操作。可以将RDD理解为一个具有容错机制的特殊集合，它提供了一种只读、只能有已存在的RDD变换而来的共享内存，然后将所有数据都加载到内存中，方便进行多次重用。

    a. 他是分布式的，可以分布在多台机器上，进行计算。
    b. 他是弹性的，计算过程中内存不够时它会和磁盘进行数据交换。
    c. 这些限制可以极大的降低自动容错开销
    d. 实质是一种更为通用的迭代并行计算框
    （1）为什么会有Spark？因为传统的并行计算模型无法有效的解决迭代计算（iterative）和交互式计算（interactive）；而Spark的使命便是解决这两个问题，这也是他存在的价值和理由。
    （2）Spark如何解决迭代计算？其主要实现思想就是RDD，把所有计算的数据保存在分布式的内存中。迭代计算通常情况下都是对同一个数据集做反复的迭代计算，数据在内存中将大大提升IO操作。这也是Spark涉及的核心：内存计算。
    （3）Spark如何实现交互式计算？因为Spark是用scala语言实现的，Spark和scala能够紧密的集成，所以Spark可以完美的运用scala的解释器，使得其中的scala可以向操作本地集合对象一样轻松操作分布式数据集。
    （4）Spark和RDD的关系？可以理解为：RDD是一种具有容错性基于内存的集群计算抽象方法，Spark则是这个抽象方法的实现。


https://blog.csdn.net/qq_22771739/article/details/82529874
问：Java 线程优先级是怎么定义的，Java 线程有几种状态？
    答：Java 线程的优先级定义为从 1 到 10 的等级，默认为 5，设置和获取线程优先级的方法是 setPriority(int newPriority) 和 getPriority()，Java 的这个优先级会被映射到操作系统中线程的优先级，不过由于操作系统各不相同，不一定都是 10 个优先级，所以 Java中不同的优先级可能会被映射到操作系统中相同的优先级，同时优先级对操作系统而言更多的是一种建议和提示而非强制，所以我们不要过于依赖优先级。
    Java Thread 可以通过 State getState() 来获取线程状态，Thread.State 枚举定义了 NEW、RUNNABLE、BLOCKED、WAITING、TIMED_WAITING、TERMINATED 六种线程状态，其实真正严格意义来说线程只有就绪、阻塞、运行三种状态，Java 线程之所以有六种状态其实是站在 Thread 对象实例的角度来看待的，具体解释如下：
    NEW（新建），表示线程 Thread 刚被创建，还没调用 start 方法。
    RUNNABLE（运行，实质对应就绪和运行状态），表示 Thread 线程正在 JVM 中运行，也就是说处于就绪和运行状态的线程在 Thread 中都表现为 RUNNABLE。
    BLOCKED（阻塞，实质对应阻塞状态），表示等待监视锁可以重新进行同步代码块中执行，此线程需要获得某个锁才能继续执行，而这个锁目前被其他线程持有，所以进入了被动的等待状态，直到抢到了那个锁才会再次进入就绪状态。处于受阻塞状态的某一线程正在等待监视器锁，以便进入一个同步的块或方法，或者在调用 wait 之后再次进入同步的块或方法。
    WAITING（等待，实质对应阻塞状态），表示此线程正处于无限期的主动等待中，直到有人唤醒它它才会再次进入就绪状态。某一线程因为调用下不带超时值的 wait、不带超时值的 join、LockSupport.park 会进入等待状态，处于等待状态的线程正等待另一个线程以执行特定操作，例如已经在某一对象上调用了 Object.wait() 的线程正等待另一个线程以便在该对象上调用 Object.notify() 或 Object.notifyAll()，或者已经调用了 Thread.join() 的线程正在等待指定线程终止。
    TIMED_WAITING（有限等待，实质对应阻塞状态），表示此线程正处于有限期的主动等待中，要么有人唤醒它，要么等待够了一定时间之后才会再次进入就绪状态，譬如调用带有超时的 sleep、join、wait 方法可能导致线程处于等待状态。
    TERMINATED（终止），表示线程执行完毕，已经退出。

1. 初始(NEW)：新创建了一个线程对象，但还没有调用start()方法。
2. 运行(RUNNABLE)：Java线程中将就绪（ready）和运行中（running）两种状态笼统的称为“运行”。
线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获取CPU的使用权，此时处于就绪状态（ready）。就绪状态的线程在获得CPU时间片后变为运行中状态（running）。
3.阻塞(BLOCKED)：表示线程阻塞于锁。
4.等待(WAITING)：进入该状态的线程需要等待其他线程做出一些特定动作（通知或中断）。
5.超时等待(TIMED_WAITING)：该状态不同于WAITING，它可以在指定的时间后自行返回。
6. 终止(TERMINATED)：表示该线程已经执行完毕。

Java中线程的状态分为6种。
    1. 初始(NEW)：新创建了一个线程对象，但还没有调用start()方法。
    2. 运行(RUNNABLE)：Java线程中将就绪（ready）和运行中（running）两种状态笼统的称为“运行”。
    线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获取CPU的使用权，此时处于就绪状态（ready）。就绪状态的线程在获得CPU时间片后变为运行中状态（running）。
    3.阻塞(BLOCKED)：表示线程阻塞于锁。
    4.等待(WAITING)：进入该状态的线程需要等待其他线程做出一些特定动作（通知或中断）。
    5.超时等待(TIMED_WAITING)：该状态不同于WAITING，它可以在指定的时间后自行返回。
    6. 终止(TERMINATED)：表示该线程已经执行完毕。

线程的状态图
1. 初始状态
实现Runnable接口和继承Thread可以得到一个线程类，new一个实例出来，线程就进入了初始状态。

2.1. 就绪状态
就绪状态只是说你资格运行，调度程序没有挑选到你，你就永远是就绪状态。
调用线程的start()方法，此线程进入就绪状态。
当前线程sleep()方法结束，其他线程join()结束，等待用户输入完毕，某个线程拿到对象锁，这些线程也将进入就绪状态。
当前线程时间片用完了，调用当前线程的yield()方法，当前线程进入就绪状态。
锁池里的线程拿到对象锁后，进入就绪状态。
2.2. 运行中状态
线程调度程序从可运行池中选择一个线程作为当前线程时线程所处的状态。这也是线程进入运行状态的唯一一种方式。

3. 阻塞状态
阻塞状态是线程阻塞在进入synchronized关键字修饰的方法或代码块(获取锁)时的状态。

4. 等待
处于这种状态的线程不会被分配CPU执行时间，它们要等待被显式地唤醒，否则会处于无限期等待的状态。

5. 超时等待
处于这种状态的线程不会被分配CPU执行时间，不过无须无限期等待被其他线程显示地唤醒，在达到一定时间后它们会自动唤醒。

6. 终止状态
当线程的run()方法完成时，或者主线程的main()方法完成时，我们就认为它终止了。这个线程对象也许是活的，但是，它已经不是一个单独执行的线程。线程一旦终止了，就不能复生。
在一个终止的线程上调用start()方法，会抛出java.lang.IllegalThreadStateException异常。
等待队列
调用obj的wait(), notify()方法前，必须获得obj锁，也就是必须写在synchronized(obj) 代码段内。
与等待队列相关的步骤和图
    1.线程1获取对象A的锁，正在使用对象A。
    2.线程1调用对象A的wait()方法。
    3.线程1释放对象A的锁，并马上进入等待队列。
    4.锁池里面的对象争抢对象A的锁。
    5.线程5获得对象A的锁，进入synchronized块，使用对象A。
    6.线程5调用对象A的notifyAll()方法，唤醒所有线程，所有线程进入同步队列。若线程5调用对象A的notify()方法，则唤醒一个线程，不知道会唤醒谁，被唤醒的那个线程进入同步队列。
    7.notifyAll()方法所在synchronized结束，线程5释放对象A的锁。
    8.同步队列的线程争抢对象锁，但线程1什么时候能抢到就不知道了。
同步队列状态
    当前线程想调用对象A的同步方法时，发现对象A的锁被别的线程占有，此时当前线程进入同步队列。简言之，同步队列里面放的都是想争夺对象锁的线程。
    当一个线程1被另外一个线程2唤醒时，1线程进入同步队列，去争夺对象锁。
    同步队列是在同步的环境下才有的概念，一个对象对应一个同步队列。
几个方法的比较
    1.Thread.sleep(long millis)，一定是当前线程调用此方法，当前线程进入TIMED_WAITING状态，但不释放对象锁，millis后线程自动苏醒进入就绪状态。作用：给其它线程执行机会的最佳方式。
    2.Thread.yield()，一定是当前线程调用此方法，当前线程放弃获取的CPU时间片，但不释放锁资源，由运行状态变为就绪状态，让OS再次选择线程。作用：让相同优先级的线程轮流执行，但并不保证一定会轮流执行。实际中无法保证yield()达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。Thread.yield()不会导致阻塞。该方法与sleep()类似，只是不能由用户指定暂停多长时间。
    3.t.join()/t.join(long millis)，当前线程里调用其它线程t的join方法，当前线程进入WAITING/TIMED_WAITING状态，当前线程不会释放已经持有的对象锁。线程t执行完毕或者millis时间到，当前线程进入就绪状态。
    4.obj.wait()，当前线程调用对象的wait()方法，当前线程释放对象锁，进入等待队列。依靠notify()/notifyAll()唤醒或者wait(long timeout) timeout时间到自动唤醒。
    5.obj.notify()唤醒在此对象监视器上等待的单个线程，选择是任意性的。notifyAll()唤醒在此对象监视器上等待的所有线程。

MYSQL查询过程:
一、执行一个查询过程概述
1.客户端发送一条查询给服务器；
2.服务器先检查查询缓存，如果命中了缓存，则立即返回存储在缓存中的结果。否则进入下一阶段；
3.服务器端进行sql解析、预处理，再由优化器生成对应的执行计划；
4.mysql根据优化器生成的执行计划，调用存储引擎的api来执行查询；
5.将结果返回给客户端；

二、查询缓存
查询缓存保存查询返回的完整结构；
命中查询缓存时，mysql会立即返回结果，跳过解析、优化和执行阶段；
查询缓存系统会跟踪查询中设计的每个表，如果这些表发生变化，和这个表相关的所有缓存数据都将失效；
判断缓存是否命中时，不会进行解析查询语句，直接使用sql语句和客户端发送过来的其他原始信息，任何字符上的不同，例如空格、注解等，都会导致缓存不命中；
当查询语句有一些不确定的数据时，则不会被缓存；
查询缓存配置参数：
query_cache_type：是否打开缓存。OFF、ON和DEMAND。DEMAND表示只有在查询语句中明确写明SQL_CACHE的语句才会放入查询缓存。eg：select sql_cache * from table_name;
query_cache_size：缓存使用的总内存空间大小，单位是字节；
query_cache_min_res_unit：分配内存块时的最小单位，较小的该值可以减少碎片导致的内存空间浪费，但会导致更频繁的内存块操作；
query_cache_limit：mysql能够缓存的最大查询结果，如果查询结果大于这个值，则不会被缓存；由于查询缓存在数据生成的时候就开始尝试缓存数据，所以当结果全部返回后，mysql才知道查询结果是否超出限制。超出之后，才会将结果从查询缓存中删除；
query_cache_wlock_invalidate：如果某个数据表被其他连接锁住，是否仍然从查询缓存中返回结果，默认OFF，表示仍然可以返回；
三、语法解析器和预处理器
mysql解析器通过关键字将sql语句进行解析，并生成对应的解析树；
mysql解析器将使用mysql语法规则验证和解析查询，eg：验证是否使用错误的关键字、使用关键字的顺序是否正确、验证引号是否前后匹配等；
预处理器根据一些mysql规则进行进一步检查解析树是否合法，eg：检查数据表和数据列是否存在，解析名字和别名是否有歧义；
下一步预处理器验证用户权限，查看用户是否有操作权限，通常很快；
四、查询优化器
优化器的作用就是找到最好的执行计划；
语法树被认为是合法后，优化器将sql语句转换为执行计划，一条查询可以有多种执行方式，最后都返回相同的结果；
生成执行计划过程
耗时较多，特别是存在许多可选的执行计划时；
在一条sql语句执行过程中将该语句对应的最终执行计划进行缓存，下一次就可以直接使用已缓存的执行计划，从而提高sql语句的执行速度；
mysql使用基于成本的优化器（CBO cost-based optimizer），会预测一个查询使用某种执行计划的成本，选择其中成本最小的一个；
优化器会根据优化规则对关系表达式进行转换，经过优化规则后会生成另一个关系表达式，原有表达式也会保留；
经过一系列转换后会生成多个执行计划，然后CBO会根据统计信息和代价模型（cost model）计算每个执行计划的cost，从中挑选cost最小的执行计划；
导致mysql优化器选择非最优执行计划的原因
mysql是根据成本计算得出的最优计划，可能执行时间并不是最短的；
有时候可能无法估算所有可能的执行计划，导致可能错过最优的执行计划；
执行计划成本估算不等同于实际执行的成本，mysql层面无法知道哪些页面在内存中，哪些在磁盘上，实际执行过程中需要多少次物理IO无法得知；
mysql不会考虑不受其控制的操作成本，eg：执行用户自定义函数的成本；
统计信息不准确，mysql依赖存储引擎提供的统计信息（每个表有多少页面、数据行和索引的长度、索引的分布等）来估计成本，InnoDB因为MVCC的架构，并不能维护一个数据表行数的精确统计信息；
mysql可以处理的优化类型
重新定义关联表的顺序；
使用等价转换原则，eg：移除一些恒成立或恒不成立的判断；
可能的表达式转换为常数表达式；
提前终止查询，使用limit；
五、查询执行引擎
查询执行引擎根据执行计划来完成整个查询；
执行计划是一个数据结构（指令树），不是和其他关系型数据库那样生成对应的字节码；
mysql根据执行计划给出的指令逐步执行，在执行过程中，有大量的操作需要调用存储引擎实现的接口来完成，这些接口即为“handler API”；
查询中每一个表由一个handler的实例表示。在优化阶段mysql就为每一个表创建了一个handler实例，优化器可以根据这些实例的接口获取表的相关信息，eg：列名、索引、统计信息等；
六、返回客户端结果
如果查询可以被缓存，mysql会在这个阶段将结果存放到查询缓存中；
mysql将结果集返回给客户端是一个增量逐步返回的过程，在查询生成第一条结果时，mysql就可以开始向客户端逐步返回结果了；
增量逐步返回的好处：服务端无须存储太多的结果，不会因为返回太多的结果而消耗太多内存；同时让客户端第一时间获得返回结果；
结果集中的每一行都会以一个满足mysql客户端/服务端通信协议的包发送，再通过tcp协议进行传输，传输过程中，可能对mysql的包进行缓存然后批量传输；


说说AQS原理吧
    AQS主要是采用volatile修饰的变量state，通过对state的CAS判断来获取锁和解锁
    如果CAS成功，就获取到锁，如果没有获取成功，线程被挂起
    并且存在等待队列和条件等待队列来park相关线程之后入队等待
    有公平和非公平两者模式来唤醒等待的线程。
    共享式和独占式两种模式
    主要是为了封装和抽象，通过封装了公共的方法，减少重复代码。


2：HashMap 的工作原理？
    HashMap 底层是 hash 数组和单向链表实现，数组中的每个元素都是链表，由 Node 内部类（实现 Map.Entry接口）实现，HashMap 通过 put & get 方法存储和获取。
    存储对象时，将 K/V 键值传给 put() 方法：
    ①、调用 hash(K) 方法计算 K 的 hash 值，然后结合数组长度，计算得数组下标；
    ②、调整数组大小（当容器中的元素个数大于 capacity * loadfactor 时，容器会进行扩容resize 为 2n）；
    ③、i.如果 K 的 hash 值在 HashMap 中不存在，则执行插入，若存在，则发生碰撞；
    ii.如果 K 的 hash 值在 HashMap 中存在，且它们两者 equals 返回 true，则更新键值对；
    iii. 如果 K 的 hash 值在 HashMap 中存在，且它们两者 equals 返回 false，则插入链表的尾部（尾插法）或者红黑树中（树的添加方式）。（JDK 1.7 之前使用头插法、JDK 1.8 使用尾插法）（注意：当碰撞导致链表大于 TREEIFY_THRESHOLD = 8 时，就把链表转换成红黑树）
    获取对象时，将 K 传给 get() 方法
    ：①、调用 hash(K) 方法（计算 K 的 hash 值）从而获取该键值所在链表的数组下标；
    ②、顺序遍历链表，equals()方法查找相同 Node 链表中 K 值对应的 V 值。
    hashCode 是定位的，存储位置；equals是定性的，比较两者是否相等。
4.你知道 hash 的实现吗？为什么要这样实现？
    JDK 1.8 中，是通过 hashCode() 的高 16 位异或低 16 位实现的：
    (h = k.hashCode()) ^ (h >>> 16)，主要是从速度，功效和质量来考虑的，减少系统的开销，也不会造成因为高位没有参与下标的计算，从而引起的碰撞。


7.HashMap中put方法的过程？
答：“调用哈希函数获取Key对应的hash值，再计算其数组下标；
如果没有出现哈希冲突，则直接放入数组；如果出现哈希冲突，则以链表的方式放在链表后面；
如果链表长度超过阀值( TREEIFY THRESHOLD==8)，就把链表转成红黑树，链表长度低于6，就把红黑树转回链表;
如果结点的key已经存在，则替换其value即可；
如果集合中的键值对大于12，调用resize方法进行数组扩容。”

8.接收窗口 rwnd 和发送窗口 cwnd
    此处涉及到二个窗口：
    接收窗口receiver window(即rwnd)
        是接收方根据自己的承受能力设置的接收缓存值大小，反映了接收方的接收能力，来做流量控制。
    拥塞窗口congestion window(即cwnd)
        是发送方根据网络拥塞程度设置的网络窗口值，发送窗口=min(rwnd，cwnd)即是接收窗口和拥塞窗口的最小值，来做拥塞控制。

9.流量控制和拥塞控制的区别
    1、拥塞控制是防止过多的数据注入到网络中，可以使网络中的路由器或链路不致过载，是一个全局性的过程。
    2、流量控制是点对点通信量的控制，是一个端到端的问题，主要就是抑制发送端发送数据的速率，以便接收端来得及接收

9.流量控制
    流量控制目的：让发送方根据网络状况动态的调整发送频率，好让接收方来得及接收。
    避免死锁：
        持续定时器（persist timer），他的作用是，发送方只要接收到了0窗口通告，就开启该定时器，周期性的向接收方发送1字节的0窗口探测报文。
    死锁问题
        1、B向A发送了零窗口的报文段后不久，B的接收缓存又有了一些存储空间。于是B向A发送了rwnd = 400的报文段，然而这个报文段在传送过程中丢失了。
        2、A一直等待收到B发送的非零窗口的通知，而B也一直等待A发送的数据，如果没有其他措施，这种相互等待的死锁局面将一直持续下去。
    死锁解决方法：
        1.TCP为每一个连接设有一个持续计时器。
        2.只要TCP连接的一方收到对方的零窗口通知，就启动持续计时器。
        3.若持续计时器设置的时间到期，就发送一个零窗口探测报文段（仅携带1字节的数据），而对方就在确认这个探测报文时给出了现在的窗口值。
        4.如果窗口值仍然是零，那么收到这个报文段的一方就重新设置持续计时器。
        5.如果窗口不是零，那么死锁的僵局就可以打破了。

10.拥塞控制
    拥塞控制的目：防止过多的数据注入到网络中，网络堵塞使得包一直到不了接收端。

9.浅析spark中的三种join方式：
    1、broadcast join：
    适用于小表与大表的join，其中小表小于10M，本质上是去用空间换时间，
    也就是将小表发送到每个大表对应的节点上，然后依次去遍历大表中的每个关联键去和对应小表中的关联键去匹配，找到相等的进行关联，并不会走shuffle过程，因此最终的文件数取决于block的个数，每个bolck是一个逻辑上的概念，
    生成的规则是在建表并落HDFS文件的时候按256M去拆分，得到最终的文件数。
    2、shuffle hash join
    适合于没有特别小的两个表进行关联的时候，默认设置的shuffle partition的个数
    是200，也就是分了200个区，然后两张表的key值分别去基于200做hash取余然后散步在每个区域中了，这样的思想先把相近的合并在一个区内，再在每个分区内去做比较key值的等值比较，就避免了大范围的遍历比较，节省了时间和内存。
    3、sort merge join
    这种适用于关联的两张表都特别大时，使用上述的两种方法加载到内存的时候对于内存的压力都非常大时，因此在2方法的基础上，hash取余之后还要分别对两张表的key值进行排序，这样去做等值比较的时候就不需要将某一方的全部数据都加载到内存进行计算了，只需要取一部分就能知道是否有相等的（比如按升序排列，某个值明显比它大了，后面肯定就不会有相等的，就不用继续比较了，节省了时间和内存），也就是在进行等值比较的时候即用即丢的。这个方法在前面进行排序的时候可能会消耗点时间，但相对于后面的时间来说，总体是大大节省了时间。

为啥分为action和transform：
    这个问题本质上讲很复杂，这是spark设计上必须要这么做，不然spark就无法干掉mapreduce。
    1. 首先我们需要理解这惰性计算
        spark将对RDD的操作分为transformation和action，action一共只有五个操作：save、count、collect、lookup、reduce。
        当然像distinct这种操作我们认为它是复合操作，中间过程包括reduce。
        只有当action执行，才会整理计算逻辑，创建job，并生成DAG，然后在DAG根据shuffle操作（宽依赖、窄依赖）更细粒度的拆分stage，启动相应数量的task计算中间结果，stage by stage的计算，就这样支撑了整个spark计算的框架。
    2. 这种惰性计算是最优做法
        所谓的惰性计算，其实只是表象，本质上都是并行计算（流水线计算），比如map1 -> filter -> map2 -> collect。a1做完map1，进入filter，此时a2进入map1...其实并不是惰性计算。
    3. 如果讲到spark设计，本质上这种设计很棒，没什么问题。同时也在考虑一个问题内存管理以及高可用。对于mapreduce来讲，在计算层面不会考虑容灾问题，因为底层hdfs的多副本会保证数据安全，但是spark就没那么幸运了，再设计时不会落盘（尽量不要），那怎么解决容灾问题？RDD采用的是dependency解决，在这种情况下拆分成stage就很好，因为这种粒度大一些，一旦数据丢失只会重启stage。如果不是惰性计算，那就倒霉了，每一个操作都将是一个RDD，对于spark来讲这种粒度太细了，管理起来不容易。

Java中static关键字：
    static 关键字可以用来修饰：属性、方法、内部类、代码块；
    static 修饰的资源属于类级别，是全体对象实例共享的资源；
    使用 static 修饰的属性，静态属性是在类的加载期间初始化的，使用类名.属性访问
　　把一个变量声明为静态变量通常基于以下三个目的：
使用静态变量的目的：
    作为共享变量使用
    减少对象的创建
    保留唯一副本
5、static修饰的数据是共享数据，对象中的存储的是特有的数据。

成员变量和静态变量的区别：
    1、生命周期的不同：
        成员变量随着对象的创建而存在随着对象的回收而释放。
        静态变量随着类的加载而存在随着类的消失而消失。

    2、调用方式不同：
        成员变量只能被对象调用。
        静态变量可以被对象调用，也可以用类名调用。（推荐用类名调用）

    3、别名不同：
        成员变量也称为实例变量。
        静态变量称为类变量。

    4、数据存储位置不同：
        成员变量数据存储在堆内存的对象中，所以也叫对象的特有数据。
        静态变量数据存储在方法区（共享数据区）的静态区，所以也叫对象的共享数据。

string为什么用final修饰：
    什么是不可变对象？
        如果一个对象，在它创建完成之后，不能再改变它的状态，那么这个对象就是不可变的。
        不能改变状态的意思是，不能改变对象内的成员变量，包括基本数据类型的值不能改变，引用类型的变量不能指向其他的对象，引用类型指向的对象的状态也不能改变。
    string底层原理
        String底层是由char数组构成，我们创建一个字符串对象的时候，其实是将字符串保存在char数组中，因为数组是引用对象，为了防止数组可变，JDK加了final修饰，但是加了final修饰的数组只是代表了引用不可变，不代表数组内容不可变，因此JDK为了真正防止不可变，又加了private修饰符。
    不可变的好处：
        1、多线程下的安全性
            因为String是不可变的，因此多线程操作下，它是安全的
        2、类加载中体现的安全性
            类加载器要用到字符串，不可变提供了安全性，以便正确的类被加载，例如你想加载java.sql.Connection类，而这个值被改成了xxx.Connection，那么会对你的数据库造成不可知的破坏。
        3、使用常量池可以节省空间
            像下面这样字符串one和two都用字面量"something"赋值。它们其实都指向同一个内存地址
            1String one = "someString";
            2String two = "someString";
            这样在大量使用字符串的情况下，可以节省内存空间，提高效率。但之所以能实现这个特性，String的不可变性是最基本的一个必要条件。要是内存里字符串内容能改来改去，这么做就完全没有意义了。

Java面向对象的三大特点：
    一、封装
        1、封装的概念
        　　封装性是面向对象编程的核心思想
        　　指的就是将描述某种实体的数据和基于这些数的操作集合到一起，形成一个封装体
        　　封装的思想保证了类内部数据结构的完整性，使用户无法轻易直接操作类的内部数据，这样降低了对内部数据的影响，提高了程序的安全性和可维护性。
        2、封装的好处
        　　只能通过规定方法访问数据
        　　隐藏类数实现细节
        　　方便修改实现
        　　方便加入控制语句　　
        3、封装的使用
        　　1）、修改属性的可见性   ——> 设为private
        　　2）、创建共有的 getter / setter方法 ——> 用于属性的读写
        　　3）、在getter / setter方法中加入属性控制语句 ——> 对属性值的合法性进行判断
   二、继承的概念和特点
   概念：
    　　继承是Java面向对象编程技术的一块基石，因为它允许创建分等级层次的类。
    　　继承就是子类继承父类的特征和行为，使得子类对象（实例）具有父类的实例域和方法，或类从父 类继承方法，使得子类具有父类相同的行为。
   三、多态
   　　将父类对象应用于子类对象的特征就是面向对象编程中的多态性的体现
   　　多态指的就是在应用程序中出现的“ 重名 ” 现象。多态性允许以统一的风格编写程序，以处理种类繁多的已存在的类及其相关类。这样既降低了维护难度，又节省了时间

多线程的执行流程：
    1、 当一个任务通过submit或者execute方法提交到线程池的时候，如果当前池中线程数（包括闲置线程）小于coolPoolSize，则创建一个线程执行该任务。
    2、如果当前线程池中线程数已经达到coolPoolSize，则将任务放入等待队列。
    3、如果任务不能入队，说明等待队列已满，若当前池中线程数小于maximumPoolSize，则创建一个临时线程（非核心线程）执行该任务。
    4、如果当前池中线程数已经等于maximumPoolSize，此时无法执行该任务，根据拒绝执行策略处理。
    注意：当池中线程数大于coolPoolSize，超过keepAliveTime时间的闲置线程会被回收掉。回收的是非核心线程，核心线程一般是不会回收的。如果设置allowCoreThreadTimeOut(true)，则核心线程在闲置keepAliveTime时间后也会被回收。
    任务队列是一个阻塞队列，线程执行完任务后会去队列取任务来执行，如果队列为空，线程就会阻塞，直到取到任务。

四种线程池：
    Java通过Executors提供四种线程池，分别为：
    1、newSingleThreadExecutor
        创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。
        底层：FinalizableDelegatedExecutorService包装的ThreadPoolExecutor实例，corePoolSize为1；maximumPoolSize为1；keepAliveTime为0L；unit为：TimeUnit.MILLISECONDS；workQueue为：new LinkedBlockingQueue<Runnable>() 无解阻塞队列
        通俗：创建只有一个线程的线程池，且线程的存活时间是无限的；当该线程正繁忙时，对于新任务会进入阻塞队列中(无界的阻塞队列)
        适用：一个任务一个任务执行的场景
    2、newFixedThreadPool
        创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。
        底层：返回ThreadPoolExecutor实例，接收参数为所设定线程数量nThread，corePoolSize为nThread，maximumPoolSize为nThread；keepAliveTime为0L(不限时)；unit为：TimeUnit.MILLISECONDS；WorkQueue为：new LinkedBlockingQueue<Runnable>() 无界阻塞队列
        通俗：创建可容纳固定数量线程的池子，每隔线程的存活时间是无限的，当池子满了就不在添加线程了；如果池中的所有线程均在繁忙状态，对于新任务会进入阻塞队列中(无界的阻塞队列)
        适用：执行长期的任务，性能好很多
        缺点：无界队列，容易造成任务阻塞
    3、newScheduledThreadPool
        创建一个可定期或者延时执行任务的定长线程池，支持定时及周期性任务执行。
        底层：创建ScheduledThreadPoolExecutor实例，corePoolSize为传递来的参数，maximumPoolSize为Integer.MAX_VALUE；keepAliveTime为0；unit为：TimeUnit.NANOSECONDS；workQueue为：new DelayedWorkQueue() 一个按超时时间升序排序的队列
        通俗：创建一个固定大小的线程池，线程池内线程存活时间无限制，线程池可以支持定时及周期性任务执行，如果所有线程均处于繁忙状态，对于新任务会进入DelayedWorkQueue队列中，这是一种按照超时时间排序的队列结构
        适用：周期性执行任务的场景

    4、newCachedThreadPool
        创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。
        底层：返回ThreadPoolExecutor实例，corePoolSize为0；maximumPoolSize为Integer.MAX_VALUE；keepAliveTime为60L；unit为TimeUnit.SECONDS；workQueue为SynchronousQueue(同步队列)
        通俗：当有新任务到来，则插入到SynchronousQueue中，由于SynchronousQueue是同步队列，因此会在池中寻找可用线程来执行，若有可以线程则执行，若没有可用线程则创建一个线程来执行该任务；若池中线程空闲时间超过指定大小，则该线程会被销毁。
        适用：执行很多短期异步的小程序或者负载较轻的服务器

线程池的7个参数：
    一、corePoolSize 线程池核心线程大小
        线程池中会维护一个最小的线程数量，即使这些线程处理空闲状态，他们也不会 被销毁，除非设置了allowCoreThreadTimeOut。这里的最小线程数量即是corePoolSize。
    二、maximumPoolSize 线程池最大线程数量
        一个任务被提交到线程池后，首先会缓存到工作队列（后面会介绍）中，如果工作队列满了，则会创建一个新线程，然后从工作队列中的取出一个任务交由新线程来处理，而将刚提交的任务放入工作队列。线程池不会无限制的去创建新线程，它会有一个最大线程数量的限制，这个数量即由maximunPoolSize来指定。
    三、keepAliveTime 空闲线程存活时间
        一个线程如果处于空闲状态，并且当前的线程数量大于corePoolSize，那么在指定时间后，这个空闲线程会被销毁，这里的指定时间由keepAliveTime来设定
    四、unit 空间线程存活时间单位
        keepAliveTime的计量单位
    五、workQueue 工作队列
        新任务被提交后，会先进入到此工作队列中，任务调度时再从队列中取出任务。jdk中提供了四种工作队列：
        ①ArrayBlockingQueue
            基于数组的有界阻塞队列，按FIFO排序。新任务进来后，会放到该队列的队尾，有界的数组可以防止资源耗尽问题。当线程池中线程数量达到corePoolSize后，再有新任务进来，则会将任务放入该队列的队尾，等待被调度。如果队列已经是满的，则创建一个新线程，如果线程数量已经达到maxPoolSize，则会执行拒绝策略。
        ②LinkedBlockingQueue
            基于链表的无界阻塞队列（其实最大容量为Interger.MAX），按照FIFO排序。由于该队列的近似无界性，当线程池中线程数量达到corePoolSize后，再有新任务进来，会一直存入该队列，而不会去创建新线程直到maxPoolSize，因此使用该工作队列时，参数maxPoolSize其实是不起作用的。
        ③SynchronousQueue
            一个不缓存任务的阻塞队列，生产者放入一个任务必须等到消费者取出这个任务。也就是说新任务进来时，不会缓存，而是直接被调度执行该任务，如果没有可用线程，则创建新线程，如果线程数量达到maxPoolSize，则执行拒绝策略。
            如果以洗盘子的比喻为例，那么这就相当于没有盘架，而是将洗好的盘子直接放入下一个空闲的烘干机中。这种实现队列的方式看似很奇怪，但由于可以直接交付工作，从而降低了将数据从生产者移动到消费者的延迟。
        ④PriorityBlockingQueue
            具有优先级的无界阻塞队列，优先级通过参数Comparator实现。
    六、threadFactory 线程工厂
        创建一个新线程时使用的工厂，可以用来设定线程名、是否为daemon线程等等
    七、handler 拒绝策略
        当工作队列中的任务已到达最大限制，并且线程池中的线程数量也达到最大限制，这时如果有新任务提交进来，该如何处理呢。这里的拒绝策略，就是解决这个问题的，jdk中提供了4中拒绝策略：
        ①CallerRunsPolicy
            该策略下，在调用者线程中直接执行被拒绝任务的run方法，除非线程池已经shutdown，则直接抛弃任务。
        ②AbortPolicy
            该策略下，直接丢弃任务，并抛出RejectedExecutionException异常。
        ③DiscardPolicy
            该策略下，直接丢弃任务，什么都不做。
        ④DiscardOldestPolicy
            该策略下，抛弃进入队列最早的那个任务，然后尝试把这次拒绝的任务放入队列
OLAP和OLTP的区别：
    联机事务处理OLTP（on-line transaction processing）
    联机分析处理OLAP（On-Line Analytical Processing）。
    1.
        OLAP是数据仓库系统的主要应用，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。
        OLAP（On-Line Analytical Processing）联机分析处理，也称为面向交易的处理过程，其基本特征是前台接收的用户数据可以立即传送到计算中心进行处理，并在很短的时间内给出处理结果，是对用户操作快速响应的方式之一。应用在数据仓库，使用对象是决策者。OLAP系统强调的是数据分析，响应速度要求没那么高。
    2.
        OLTP是传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行交易。
        OLTP（On-Line Transaction Processing）联机事务处理，它使分析人员能够迅速、一致、交互地从各个方面观察信息，以达到深入理解数据的目的。它具有FASMI(Fast Analysis of Shared Multidimensional Information)，即共享多维信息的快速分析的特征。主要应用是传统关系型数据库。OLTP系统强调的是内存效率，实时性比较高。
flink savepoint checkpoint区别
    功能的原理是一样的, 只是目的不同, 一个是自动的备份, 另一个是手动的保持状态, 用做版本升级/服务重启等
flink checkpoint原理
    意义: 被checkpoint保存的每个subtask的状态只有raw state和managed state两种。
    raw state是用户自己进行序列化，而managed state是在operator生命周期初始化时就被注册到backend storage对象中了，在进行checkpoint时，会直接拿到注册的state进行保存（中间会调用回调函数，在UDF中对state进行赋值）。
    所以checkpoint的state不是很大的数据。
    如何做到checkpoint:
        理想情况下, checkpoint是最好可以把输入流停掉, 然后保持这一时刻 所有分区的快照
        但是这样在工程上不合理, 所以用了Chandy-Lamport算法 做一个分布式的快照
        在checkpoint触发时刻，Job Manager会往所有Source的流中放入一个barrier。barrier包含当前checkpoint的ID
        当barrier经过一个subtask时，即表示当前这个subtask处于checkpoint触发的“时刻”，他就会立即将barrier发往下游，并执行checkpoint方法将当前的state存入backend storage

hive-sql,spark-sql的原理：
    然后就是问hive sql的执行原理, hive/spark sql/ mysql/ calcite 其实都有着共性
    就是分为了 sql语法词法解析为抽象语法树AST -> 逻辑计划生成和优化 -> 物理计划生成和优化
    比如sql语法词法解析为抽象语法树AST
    calcite用了javaCC catalyst用了anltr4 ,巴拉巴拉 然后是逻辑计划的生成, 然后是逻辑计划的优化
    逻辑计划生成和优化：属于基于关系型代数来对sql语法进行同义替换的过程
    物理疾患生成和优化：然后到了具体的物理执行计划的时候 才有各自的区别, 比如hive是把相关的逻辑计划翻译成map reduce等操作, spark sql是把他翻译成rdd直接的操作 其实整体来看 殊途同归

Kafka多副本之间数据如何同步？
    多个副本之间数据是如何同步的？其实任何一个 Partition，只有 Leader 是对外提供读写服务的。
    也就是说，如果有一个客户端往一个 Partition 写入数据，此时一般就是写入这个 Partition 的 Leader 副本。
    然后 Leader 副本接收到数据之后，Follower 副本会不停的给它发送请求尝试去拉取最新的数据，拉取到自己本地后，写入磁盘中。
Kafka如何保证可靠性和一致性：
    1.Kafka 的分区多副本架构是 Kafka 可靠性保证的核心，把消息写入多个副本可以使 Kafka 在发生崩溃时仍能保证消息的持久性。
    2.Producer 往 Broker 发送消息，在 Producer 里面提供了消息确认机制，也就是说我们可以通过配置来决定消息发送到对应分区的几个副本才算消息发送成功
        1.acks = 0：意味着如果生产者能够通过网络把消息发送出去，那么就认为消息已成功写入 Kafka。
        2.acks = 1：意思就是说只要 Partition Leader 接收到消息而且写入本地磁盘了，就认为成功了，不管它其他的 Follower 有没有同步过去这条消息了。
                    意味若 Leader 在收到消息并把它写入到分区数据文件（不一定同步到磁盘上）时会返回确认或错误响应。
                    这种设置其实是 Kafka 默认的设置
                    万一 Partition Leader 刚刚接收到消息，Follower 还没来得及同步过去，结果 Leader 所在的 Broker 宕机了，此时也会导致这条消息丢失，因为人家客户端已经认为发送成功了。
        3.acks = all：这个意思就是说，Partition Leader 接收到消息之后，还必须要求 ISR 列表里跟 Leader 保持同步的那些 Follower 都要把消息同步过去，才能认为这条消息是写入成功了。
                    意味着 Leader 在返回确认或错误响应之前，会等待所有同步副本都收到悄息。
    3.leader选举机制
        ISR（in-sync replicas）列表。每个分区的 leader 会维护一个 ISR 列表，ISR 列表里面就是 follower 副本的 Borker 编号
        只有跟得上 Leader 的 follower 副本才能加入到 ISR 里面
        通过replica.lag.time.max.ms 参数进行配置。
        所以当 Leader 挂掉了，而且 unclean.leader.election.enable=false 的情况下
        Kafka 会从 ISR 列表中选择第一个 follower 作为新的 Leader
        因为这个分区拥有最新的已经 committed 的消息。通过这个可以保证已经 committed 的消息的数据可靠性。
Kafka的数据一致性：
    数据一致性主要是说不论是老的 Leader 还是新选举的 Leader，Consumer 都能读到一样的数据。那么 Kafka 是如何实现的呢？
    只有 High Water Mark 以上的消息才支持 Consumer 读取，类似于木桶原理。而 High Water Mark 取决于 ISR 列表里面偏移量最小的分区，对应于上图的副本2，这个很类似于木桶原理。
    这样做的原因是还没有被足够多副本复制的消息被认为是“不安全”的，如果 Leader 发生崩溃，另一个副本成为新 Leader，那么这些消息很可能丢失了。如果我们允许消费者读取这些消息，可能就会破坏一致性。试想，一个消费者从当前 Leader（副本0） 读取并处理了 Message4，这个时候 Leader 挂掉了，选举了副本1为新的 Leader，这时候另一个消费者再去从新的 Leader 读取消息，发现这个消息其实并不存在，这就导致了数据不一致性问题。
    当然，引入了 High Water Mark 机制，会导致 Broker 间的消息复制因为某些原因变慢，那么消息到达消费者的时间也会随之变长（因为我们会先等待消息复制完毕）。延迟时间可以通过参数 replica.lag.time.max.ms 参数配置，它指定了副本在复制消息时可被允许的最大延迟时间。

Flink反压：
    Flink 内部是基于 producer-consumer 模型来进行消息传递的，Flink的反压设计也是基于这个模型。Flink 使用了高效有界的分布式阻塞队列，就像 Java 通用的阻塞队列（BlockingQueue）一样。下游消费者消费变慢，上游就会受到阻塞。


上下文切换的开销：
    上下文切换的开销包括直接开销和间接开销。
直接开销有如下几点：（时间开销）
    操作系统保存回复上下文所需的开销
    线程调度器调度线程的开销

间接开销有如下几点：（缓存开销）
    处理器高速缓存重新加载的开销
    上下文切换可能导致整个一级高速缓存中的内容被冲刷，即被写入到下一级高速缓存或主存